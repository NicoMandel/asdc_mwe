{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eec646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f4bf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required functions, classes\n",
    "from sahi import AutoDetectionModel\n",
    "from sahi.predict import get_sliced_prediction\n",
    "from sahi.utils.file import list_files\n",
    "from sahi.utils.cv import IMAGE_EXTENSIONS, read_image_as_pil\n",
    "from argparse import ArgumentParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c95ad74",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = ArgumentParser(description=\"File for creating labels on a folder of inference images using SAHI\")\n",
    "    parser.add_argument(\"-i\", \"--input\", required=True, type=str, help=\"Location of the input folder\")\n",
    "    parser.add_argument(\"-o\", \"--output\", required=True, help=\"which output folder to put the labels to\")\n",
    "    args = parser.parse_args()\n",
    "    return vars(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e2729a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Converting with custom functions:\n",
    "# https://haobin-tan.netlify.app/ai/computer-vision/object-detection/coco-json-to-yolo-txt/\n",
    "def convert_bbox_coco2yolo(img_w, img_h, bbox):\n",
    "    x_tl, y_tl, w, h = bbox\n",
    "    dw = 1.0 / img_w\n",
    "    dh = 1.0 / img_h\n",
    "\n",
    "    x_c = x_tl + w / 2.\n",
    "    y_c = y_tl + h / 2.\n",
    "\n",
    "    x = x_c * dw\n",
    "    y = y_c * dh\n",
    "\n",
    "    x = x_c * dw\n",
    "    y = y_c * dh\n",
    "    w = w*dw\n",
    "    h = h*dh\n",
    "    return x, y, w, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d956e1d6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def convert_pred_to_txt(pred, target_dir, img_name : str = \"labels\"):\n",
    "    # print(pred)\n",
    "    img_w = pred.image_width\n",
    "    img_h = pred.image_height\n",
    "    # cats = [bbox.to_coco_annotation()[\"category_id\"] for bbox in pred.object_prediction_list]\n",
    "    cc_annot = [bbox.to_coco_annotation() for bbox in pred.object_prediction_list]\n",
    "    bboxes = [an.bbox for an in cc_annot]\n",
    "    cats = [an.category_id for an in cc_annot]\n",
    "    yolo_bboxes = [convert_bbox_coco2yolo(img_w, img_h, bbox) for bbox in bboxes]\n",
    "    if not yolo_bboxes: return\n",
    "    cat = 0\n",
    "    outf = os.path.join(target_dir, img_name + \".txt\")\n",
    "    with open(outf, \"w\") as out:\n",
    "        for x, y, w, h in yolo_bboxes:\n",
    "            out.write(f\"{cat} {x:.6f} {y:.6f} {w:.6f} {h:.6f}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a842e82",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    args = parse_args()\n",
    "    yolov5_model_path = \"yolov5/ohw/combined_m_2/weights/best.pt\"\n",
    "    model_type = \"yolov5\"\n",
    "    model_path = yolov5_model_path\n",
    "    model_device = \"cuda:0\" # or 'cuda:0'\n",
    "    model_confidence_threshold = 0.4\n",
    "\n",
    "    slice_height = 1280\n",
    "    slice_width = 1280\n",
    "    overlap_height_ratio = 0.3\n",
    "    overlap_width_ratio = 0.3\n",
    "\n",
    "    source_image_dir = args[\"input\"]\n",
    "    target_dir = args[\"output\"]\n",
    "    # fullp = os.path.abspath(target_dir)\n",
    "    # tgt_proj = \n",
    "    # # \"demo_data/\"\n",
    "    # project = \"SAHI\"\n",
    "    # name = \"test_ds\"\n",
    "\n",
    "    # Get the model\n",
    "    detection_model = AutoDetectionModel.from_pretrained(\n",
    "        model_type='yolov5',\n",
    "        model_path=model_path,\n",
    "        confidence_threshold=0.4,\n",
    "        device=\"cuda:0\", # or 'cuda:0'\n",
    "    )\n",
    "\n",
    "    # Get single image result prediction\n",
    "    image_iterator = list_files(\n",
    "        directory=source_image_dir,\n",
    "        contains=IMAGE_EXTENSIONS,\n",
    "        verbose=2,\n",
    "    )\n",
    "\n",
    "    for ind, image_path in enumerate(\n",
    "            tqdm(image_iterator, f\"Performing inference on {source_image_dir}\")\n",
    "        ):\n",
    "        image_as_pil = read_image_as_pil(image_path)\n",
    "        # test_img = \"data/OHW/Inference/test_ds/DSC00009.png\"\n",
    "        result = get_sliced_prediction(\n",
    "            image_as_pil,\n",
    "            detection_model,\n",
    "            slice_height = 1280,\n",
    "            slice_width = 1280,\n",
    "            overlap_height_ratio = 0.5,\n",
    "            overlap_width_ratio = 0.5\n",
    "        )\n",
    "        imgf = os.path.basename(image_path).split(\".\")[0]\n",
    "        convert_pred_to_txt(result, target_dir, imgf)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
